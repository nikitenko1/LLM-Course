{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c5758bd",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5478732",
   "metadata": {},
   "source": [
    "This course will teach you about large language models (LLMs) and natural language processing (NLP) using libraries from the Hugging Face ecosystem â€” ðŸ¤— Transformers, ðŸ¤— Datasets, ðŸ¤— Tokenizers, and ðŸ¤— Accelerate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408d44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NLP (Natural Language Processing) is the broader field focused on enabling computers to understand, interpret, and \n",
    "generate human language. \n",
    "NLP encompasses many techniques and tasks such as sentiment analysis, named entity recognition, and machine translation.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LLMs (Large Language Models) are a powerful subset of NLP models characterized by their massive size, \n",
    "extensive training data, and ability to perform a wide range of language tasks with minimal task-specific training. \n",
    "\n",
    "Models like the Llama, GPT, or Claude series are examples of LLMs that have revolutionized whatâ€™s possible in NLP\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51403722",
   "metadata": {},
   "source": [
    "![Sample Image](images/summary.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c8d11",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
